{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/encode/encode.txt\n",
      "/kaggle/input/cloud-multi-label-classification/MultilabelClassification.csv\n",
      "/kaggle/input/cloud-multi-label-classification/multilabel_with_encoding.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageFile</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Gravel</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>value</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.        13.440712   0.         0.         ...</td>\n",
       "      <td>[0. 0. 0. ... 1. 1. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[  0.           0.           0.           0.  ...</td>\n",
       "      <td>[0.         0.         0.74901961 ... 0.      ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0031ae9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.        43.654854   0.         0.         ...</td>\n",
       "      <td>[1.         1.         1.         ... 0.501960...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0035239.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 5.093945    3.637504    0.          0.      ...</td>\n",
       "      <td>[0. 0. 0. ... 1. 1. 1.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003994e.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.         29.340788    0.          0.      ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>ffcedf2.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 6.388779   38.486305    0.          0.      ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ffd11b6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.8761144  24.618515    0.          0.      ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ffd3dfb.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.          0.          0.          0.      ...</td>\n",
       "      <td>[0.         0.         0.         ... 0.250980...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ffd6680.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.4262094e-01 2.0430412e+01 0.0000000e+00 0.0...</td>\n",
       "      <td>[0. 0. 0. ... 1. 0. 1.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ffea4f4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[  0.           7.3574634    0.           0.  ...</td>\n",
       "      <td>[1. 0. 0. ... 0. 0. 1.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 1.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5546 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageFile  Fish  Flower  Gravel  Sugar  \\\n",
       "0     0011165.jpg     1       1       0      0   \n",
       "1     002be4f.jpg     1       1       0      1   \n",
       "2     0031ae9.jpg     1       1       0      1   \n",
       "3     0035239.jpg     0       1       1      0   \n",
       "4     003994e.jpg     1       0       1      1   \n",
       "...           ...   ...     ...     ...    ...   \n",
       "5541  ffcedf2.jpg     1       0       0      0   \n",
       "5542  ffd11b6.jpg     0       1       0      1   \n",
       "5543  ffd3dfb.jpg     0       0       0      1   \n",
       "5544  ffd6680.jpg     0       1       1      0   \n",
       "5545  ffea4f4.jpg     0       1       0      0   \n",
       "\n",
       "                                                  value  \\\n",
       "0     [ 0.        13.440712   0.         0.         ...   \n",
       "1     [  0.           0.           0.           0.  ...   \n",
       "2     [ 0.        43.654854   0.         0.         ...   \n",
       "3     [ 5.093945    3.637504    0.          0.      ...   \n",
       "4     [ 0.         29.340788    0.          0.      ...   \n",
       "...                                                 ...   \n",
       "5541  [ 6.388779   38.486305    0.          0.      ...   \n",
       "5542  [ 1.8761144  24.618515    0.          0.      ...   \n",
       "5543  [ 0.          0.          0.          0.      ...   \n",
       "5544  [7.4262094e-01 2.0430412e+01 0.0000000e+00 0.0...   \n",
       "5545  [  0.           7.3574634    0.           0.  ...   \n",
       "\n",
       "                                                 actual  \\\n",
       "0                               [0. 0. 0. ... 1. 1. 0.]   \n",
       "1     [0.         0.         0.74901961 ... 0.      ...   \n",
       "2     [1.         1.         1.         ... 0.501960...   \n",
       "3                               [0. 0. 0. ... 1. 1. 1.]   \n",
       "4                               [0. 0. 0. ... 0. 0. 0.]   \n",
       "...                                                 ...   \n",
       "5541                            [0. 0. 0. ... 0. 0. 1.]   \n",
       "5542                            [0. 0. 0. ... 0. 0. 0.]   \n",
       "5543  [0.         0.         0.         ... 0.250980...   \n",
       "5544                            [0. 0. 0. ... 1. 0. 1.]   \n",
       "5545                            [1. 0. 0. ... 0. 0. 1.]   \n",
       "\n",
       "                    predicted  \n",
       "0     [0. 0. 0. ... 0. 0. 1.]  \n",
       "1     [0. 0. 0. ... 0. 0. 1.]  \n",
       "2     [0. 0. 0. ... 0. 0. 1.]  \n",
       "3     [0. 0. 0. ... 0. 0. 1.]  \n",
       "4     [0. 0. 0. ... 0. 0. 1.]  \n",
       "...                       ...  \n",
       "5541  [0. 0. 0. ... 0. 0. 1.]  \n",
       "5542  [0. 0. 0. ... 0. 0. 1.]  \n",
       "5543  [0. 0. 0. ... 0. 0. 1.]  \n",
       "5544  [0. 0. 0. ... 0. 0. 1.]  \n",
       "5545  [0. 0. 0. ... 0. 0. 1.]  \n",
       "\n",
       "[5546 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/cloud-multi-label-classification/multilabel_with_encoding.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "encoded_images = []\n",
    "for i in range(len(df)):\n",
    "    a = (df['value'][i].split())\n",
    "    \n",
    "    \n",
    "    #print(a)\n",
    "    if(len(a)!=116):\n",
    "        if(len(a)==114):\n",
    "            a[0]=a[0].split('[')[1]\n",
    "            a[-1]=a[-1].split(']')[0]\n",
    "        else:\n",
    "            if(a[0]=='['):\n",
    "                a = a[1:]\n",
    "            elif(a[-1]==']'):\n",
    "                a = a[:-1]\n",
    "            if('[' in a[0]):\n",
    "                a[0]=a[0].split('[')[1]\n",
    "            elif(']' in a[-1]):\n",
    "                a[-1]=a[-1].split(']')[0]\n",
    "        print(len(a))\n",
    "    else:\n",
    "        a=a[1:-1]\n",
    "    a = [float(j) for j in a]\n",
    "    encoded_images.append(a)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(len(df)):\n",
    "    output = df[df['ImageFile'] == df['ImageFile'][i]]\n",
    "    if(len(output)):\n",
    "        label = []\n",
    "        output = output.reset_index(drop=True)\n",
    "        label.append(output['Fish'][0])\n",
    "        label.append(output['Flower'][0])\n",
    "        label.append(output['Gravel'][0])\n",
    "        label.append(output['Sugar'][0])\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5546, 114)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = np.array(encoded_images)\n",
    "print(encoded.shape)\n",
    "label = np.array(y)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 57)                228       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 232       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,015\n",
      "Trainable params: 6,901\n",
      "Non-trainable params: 114\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size =64\n",
    "model = Sequential()\n",
    "model.add(Dense(57,input_shape=(114,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# use a *softmax* activation for single-label classification\n",
    "# and *sigmoid* activation for multi-label classification\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.compile(optimizer=\"Adam\",loss='binary_crossentropy',metrics=['accuracy',f1_m,precision_m, recall_m])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4436, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(encoded,label,test_size=0.2)\n",
    "x_train = x_train.reshape(len(x_train),114)\n",
    "x_test  = x_test.reshape(len(x_test),114)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4436 samples, validate on 1110 samples\n",
      "Epoch 1/50\n",
      "4436/4436 [==============================] - 1s 145us/step - loss: 0.9269 - accuracy: 0.5099 - f1_m: 0.5271 - precision_m: 0.5411 - recall_m: 0.5153 - val_loss: 0.8924 - val_accuracy: 0.5218 - val_f1_m: 0.5631 - val_precision_m: 0.5586 - val_recall_m: 0.5686\n",
      "Epoch 2/50\n",
      "4436/4436 [==============================] - 0s 47us/step - loss: 0.8213 - accuracy: 0.5258 - f1_m: 0.5499 - precision_m: 0.5570 - recall_m: 0.5449 - val_loss: 0.7312 - val_accuracy: 0.5351 - val_f1_m: 0.5874 - val_precision_m: 0.5648 - val_recall_m: 0.6134\n",
      "Epoch 3/50\n",
      "4436/4436 [==============================] - 0s 47us/step - loss: 0.7830 - accuracy: 0.5346 - f1_m: 0.5680 - precision_m: 0.5614 - recall_m: 0.5766 - val_loss: 0.7007 - val_accuracy: 0.5550 - val_f1_m: 0.6066 - val_precision_m: 0.5798 - val_recall_m: 0.6372\n",
      "Epoch 4/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.7448 - accuracy: 0.5451 - f1_m: 0.5777 - precision_m: 0.5703 - recall_m: 0.5866 - val_loss: 0.6906 - val_accuracy: 0.5559 - val_f1_m: 0.6070 - val_precision_m: 0.5823 - val_recall_m: 0.6354\n",
      "Epoch 5/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.7260 - accuracy: 0.5515 - f1_m: 0.5891 - precision_m: 0.5738 - recall_m: 0.6066 - val_loss: 0.6855 - val_accuracy: 0.5613 - val_f1_m: 0.6074 - val_precision_m: 0.5898 - val_recall_m: 0.6279\n",
      "Epoch 6/50\n",
      "4436/4436 [==============================] - 0s 49us/step - loss: 0.7119 - accuracy: 0.5534 - f1_m: 0.5905 - precision_m: 0.5761 - recall_m: 0.6070 - val_loss: 0.6813 - val_accuracy: 0.5595 - val_f1_m: 0.6049 - val_precision_m: 0.5873 - val_recall_m: 0.6258\n",
      "Epoch 7/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.7023 - accuracy: 0.5581 - f1_m: 0.5927 - precision_m: 0.5796 - recall_m: 0.6078 - val_loss: 0.6796 - val_accuracy: 0.5601 - val_f1_m: 0.6127 - val_precision_m: 0.5870 - val_recall_m: 0.6425\n",
      "Epoch 8/50\n",
      "4436/4436 [==============================] - 0s 49us/step - loss: 0.6918 - accuracy: 0.5670 - f1_m: 0.6041 - precision_m: 0.5891 - recall_m: 0.6212 - val_loss: 0.6778 - val_accuracy: 0.5606 - val_f1_m: 0.6124 - val_precision_m: 0.5860 - val_recall_m: 0.6431\n",
      "Epoch 9/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6853 - accuracy: 0.5657 - f1_m: 0.6023 - precision_m: 0.5872 - recall_m: 0.6196 - val_loss: 0.6768 - val_accuracy: 0.5682 - val_f1_m: 0.6246 - val_precision_m: 0.5919 - val_recall_m: 0.6624\n",
      "Epoch 10/50\n",
      "4436/4436 [==============================] - 0s 56us/step - loss: 0.6821 - accuracy: 0.5727 - f1_m: 0.6114 - precision_m: 0.5945 - recall_m: 0.6306 - val_loss: 0.6758 - val_accuracy: 0.5673 - val_f1_m: 0.6167 - val_precision_m: 0.5947 - val_recall_m: 0.6420\n",
      "Epoch 11/50\n",
      "4436/4436 [==============================] - 0s 54us/step - loss: 0.6795 - accuracy: 0.5783 - f1_m: 0.6164 - precision_m: 0.5944 - recall_m: 0.6416 - val_loss: 0.6744 - val_accuracy: 0.5680 - val_f1_m: 0.6192 - val_precision_m: 0.5936 - val_recall_m: 0.6487\n",
      "Epoch 12/50\n",
      "4436/4436 [==============================] - 0s 54us/step - loss: 0.6770 - accuracy: 0.5766 - f1_m: 0.6169 - precision_m: 0.5947 - recall_m: 0.6415 - val_loss: 0.6744 - val_accuracy: 0.5667 - val_f1_m: 0.6159 - val_precision_m: 0.5939 - val_recall_m: 0.6405\n",
      "Epoch 13/50\n",
      "4436/4436 [==============================] - 0s 52us/step - loss: 0.6754 - accuracy: 0.5742 - f1_m: 0.6105 - precision_m: 0.5946 - recall_m: 0.6285 - val_loss: 0.6744 - val_accuracy: 0.5644 - val_f1_m: 0.6135 - val_precision_m: 0.5944 - val_recall_m: 0.6355\n",
      "Epoch 14/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6714 - accuracy: 0.5812 - f1_m: 0.6197 - precision_m: 0.5990 - recall_m: 0.6431 - val_loss: 0.6749 - val_accuracy: 0.5626 - val_f1_m: 0.6116 - val_precision_m: 0.5913 - val_recall_m: 0.6346\n",
      "Epoch 15/50\n",
      "4436/4436 [==============================] - 0s 52us/step - loss: 0.6709 - accuracy: 0.5829 - f1_m: 0.6232 - precision_m: 0.5987 - recall_m: 0.6510 - val_loss: 0.6742 - val_accuracy: 0.5671 - val_f1_m: 0.6124 - val_precision_m: 0.5988 - val_recall_m: 0.6278\n",
      "Epoch 16/50\n",
      "4436/4436 [==============================] - 0s 54us/step - loss: 0.6721 - accuracy: 0.5783 - f1_m: 0.6149 - precision_m: 0.5980 - recall_m: 0.6338 - val_loss: 0.6739 - val_accuracy: 0.5678 - val_f1_m: 0.6159 - val_precision_m: 0.5967 - val_recall_m: 0.6379\n",
      "Epoch 17/50\n",
      "4436/4436 [==============================] - 0s 50us/step - loss: 0.6680 - accuracy: 0.5850 - f1_m: 0.6177 - precision_m: 0.6021 - recall_m: 0.6356 - val_loss: 0.6742 - val_accuracy: 0.5707 - val_f1_m: 0.6201 - val_precision_m: 0.5978 - val_recall_m: 0.6454\n",
      "Epoch 18/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6687 - accuracy: 0.5870 - f1_m: 0.6245 - precision_m: 0.6037 - recall_m: 0.6479 - val_loss: 0.6735 - val_accuracy: 0.5680 - val_f1_m: 0.6184 - val_precision_m: 0.5968 - val_recall_m: 0.6429\n",
      "Epoch 19/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6688 - accuracy: 0.5906 - f1_m: 0.6289 - precision_m: 0.6067 - recall_m: 0.6542 - val_loss: 0.6735 - val_accuracy: 0.5714 - val_f1_m: 0.6170 - val_precision_m: 0.6028 - val_recall_m: 0.6333\n",
      "Epoch 20/50\n",
      "4436/4436 [==============================] - 0s 54us/step - loss: 0.6660 - accuracy: 0.5920 - f1_m: 0.6272 - precision_m: 0.6112 - recall_m: 0.6455 - val_loss: 0.6739 - val_accuracy: 0.5689 - val_f1_m: 0.6140 - val_precision_m: 0.5983 - val_recall_m: 0.6317\n",
      "Epoch 21/50\n",
      "4436/4436 [==============================] - 0s 52us/step - loss: 0.6656 - accuracy: 0.5915 - f1_m: 0.6268 - precision_m: 0.6095 - recall_m: 0.6463 - val_loss: 0.6741 - val_accuracy: 0.5703 - val_f1_m: 0.6189 - val_precision_m: 0.5995 - val_recall_m: 0.6413\n",
      "Epoch 22/50\n",
      "4436/4436 [==============================] - 0s 52us/step - loss: 0.6657 - accuracy: 0.5883 - f1_m: 0.6257 - precision_m: 0.6040 - recall_m: 0.6504 - val_loss: 0.6748 - val_accuracy: 0.5669 - val_f1_m: 0.6194 - val_precision_m: 0.5944 - val_recall_m: 0.6479\n",
      "Epoch 23/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6653 - accuracy: 0.5923 - f1_m: 0.6296 - precision_m: 0.6108 - recall_m: 0.6511 - val_loss: 0.6750 - val_accuracy: 0.5707 - val_f1_m: 0.6213 - val_precision_m: 0.5982 - val_recall_m: 0.6475\n",
      "Epoch 24/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6646 - accuracy: 0.5899 - f1_m: 0.6281 - precision_m: 0.6066 - recall_m: 0.6524 - val_loss: 0.6755 - val_accuracy: 0.5685 - val_f1_m: 0.6166 - val_precision_m: 0.5979 - val_recall_m: 0.6377\n",
      "Epoch 25/50\n",
      "4436/4436 [==============================] - 0s 54us/step - loss: 0.6635 - accuracy: 0.5893 - f1_m: 0.6264 - precision_m: 0.6060 - recall_m: 0.6495 - val_loss: 0.6755 - val_accuracy: 0.5685 - val_f1_m: 0.6184 - val_precision_m: 0.5975 - val_recall_m: 0.6425\n",
      "Epoch 26/50\n",
      "4436/4436 [==============================] - 0s 56us/step - loss: 0.6648 - accuracy: 0.5937 - f1_m: 0.6321 - precision_m: 0.6109 - recall_m: 0.6560 - val_loss: 0.6758 - val_accuracy: 0.5667 - val_f1_m: 0.6165 - val_precision_m: 0.5964 - val_recall_m: 0.6394\n",
      "Epoch 27/50\n",
      "4436/4436 [==============================] - 0s 58us/step - loss: 0.6627 - accuracy: 0.5967 - f1_m: 0.6363 - precision_m: 0.6106 - recall_m: 0.6660 - val_loss: 0.6765 - val_accuracy: 0.5640 - val_f1_m: 0.6193 - val_precision_m: 0.5928 - val_recall_m: 0.6499\n",
      "Epoch 28/50\n",
      "4436/4436 [==============================] - 0s 55us/step - loss: 0.6631 - accuracy: 0.5932 - f1_m: 0.6313 - precision_m: 0.6086 - recall_m: 0.6570 - val_loss: 0.6767 - val_accuracy: 0.5653 - val_f1_m: 0.6162 - val_precision_m: 0.5943 - val_recall_m: 0.6412\n",
      "Epoch 29/50\n",
      "4436/4436 [==============================] - 0s 52us/step - loss: 0.6615 - accuracy: 0.5959 - f1_m: 0.6344 - precision_m: 0.6114 - recall_m: 0.6605 - val_loss: 0.6776 - val_accuracy: 0.5660 - val_f1_m: 0.6200 - val_precision_m: 0.5940 - val_recall_m: 0.6496\n",
      "Epoch 30/50\n",
      "4436/4436 [==============================] - 0s 55us/step - loss: 0.6628 - accuracy: 0.5893 - f1_m: 0.6278 - precision_m: 0.6064 - recall_m: 0.6518 - val_loss: 0.6773 - val_accuracy: 0.5655 - val_f1_m: 0.6150 - val_precision_m: 0.5955 - val_recall_m: 0.6374\n",
      "Epoch 31/50\n",
      "4436/4436 [==============================] - 0s 53us/step - loss: 0.6603 - accuracy: 0.5982 - f1_m: 0.6362 - precision_m: 0.6143 - recall_m: 0.6607 - val_loss: 0.6779 - val_accuracy: 0.5651 - val_f1_m: 0.6191 - val_precision_m: 0.5935 - val_recall_m: 0.6481\n",
      "Epoch 32/50\n",
      "4436/4436 [==============================] - 0s 47us/step - loss: 0.6598 - accuracy: 0.5986 - f1_m: 0.6389 - precision_m: 0.6133 - recall_m: 0.6686 - val_loss: 0.6787 - val_accuracy: 0.5613 - val_f1_m: 0.6134 - val_precision_m: 0.5928 - val_recall_m: 0.6368\n",
      "Epoch 33/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6585 - accuracy: 0.6016 - f1_m: 0.6395 - precision_m: 0.6161 - recall_m: 0.6662 - val_loss: 0.6790 - val_accuracy: 0.5633 - val_f1_m: 0.6111 - val_precision_m: 0.5951 - val_recall_m: 0.6298\n",
      "Epoch 34/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6582 - accuracy: 0.6008 - f1_m: 0.6371 - precision_m: 0.6147 - recall_m: 0.6622 - val_loss: 0.6798 - val_accuracy: 0.5595 - val_f1_m: 0.6114 - val_precision_m: 0.5896 - val_recall_m: 0.6367\n",
      "Epoch 35/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.6590 - accuracy: 0.6017 - f1_m: 0.6413 - precision_m: 0.6155 - recall_m: 0.6701 - val_loss: 0.6800 - val_accuracy: 0.5628 - val_f1_m: 0.6157 - val_precision_m: 0.5920 - val_recall_m: 0.6429\n",
      "Epoch 36/50\n",
      "4436/4436 [==============================] - 0s 47us/step - loss: 0.6565 - accuracy: 0.6044 - f1_m: 0.6442 - precision_m: 0.6161 - recall_m: 0.6763 - val_loss: 0.6811 - val_accuracy: 0.5590 - val_f1_m: 0.6084 - val_precision_m: 0.5897 - val_recall_m: 0.6298\n",
      "Epoch 37/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.6561 - accuracy: 0.6067 - f1_m: 0.6467 - precision_m: 0.6192 - recall_m: 0.6778 - val_loss: 0.6819 - val_accuracy: 0.5635 - val_f1_m: 0.6098 - val_precision_m: 0.5960 - val_recall_m: 0.6255\n",
      "Epoch 38/50\n",
      "4436/4436 [==============================] - 0s 44us/step - loss: 0.6551 - accuracy: 0.6058 - f1_m: 0.6429 - precision_m: 0.6211 - recall_m: 0.6675 - val_loss: 0.6825 - val_accuracy: 0.5637 - val_f1_m: 0.6114 - val_precision_m: 0.5956 - val_recall_m: 0.6297\n",
      "Epoch 39/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6556 - accuracy: 0.6087 - f1_m: 0.6448 - precision_m: 0.6229 - recall_m: 0.6695 - val_loss: 0.6830 - val_accuracy: 0.5619 - val_f1_m: 0.6139 - val_precision_m: 0.5911 - val_recall_m: 0.6398\n",
      "Epoch 40/50\n",
      "4436/4436 [==============================] - 0s 44us/step - loss: 0.6554 - accuracy: 0.6083 - f1_m: 0.6465 - precision_m: 0.6214 - recall_m: 0.6750 - val_loss: 0.6832 - val_accuracy: 0.5642 - val_f1_m: 0.6106 - val_precision_m: 0.5943 - val_recall_m: 0.6289\n",
      "Epoch 41/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6539 - accuracy: 0.6093 - f1_m: 0.6434 - precision_m: 0.6242 - recall_m: 0.6655 - val_loss: 0.6836 - val_accuracy: 0.5619 - val_f1_m: 0.6156 - val_precision_m: 0.5902 - val_recall_m: 0.6444\n",
      "Epoch 42/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6553 - accuracy: 0.6063 - f1_m: 0.6445 - precision_m: 0.6206 - recall_m: 0.6717 - val_loss: 0.6840 - val_accuracy: 0.5633 - val_f1_m: 0.6148 - val_precision_m: 0.5916 - val_recall_m: 0.6411\n",
      "Epoch 43/50\n",
      "4436/4436 [==============================] - 0s 44us/step - loss: 0.6534 - accuracy: 0.6093 - f1_m: 0.6453 - precision_m: 0.6230 - recall_m: 0.6709 - val_loss: 0.6843 - val_accuracy: 0.5637 - val_f1_m: 0.6190 - val_precision_m: 0.5918 - val_recall_m: 0.6501\n",
      "Epoch 44/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6539 - accuracy: 0.6062 - f1_m: 0.6449 - precision_m: 0.6211 - recall_m: 0.6720 - val_loss: 0.6846 - val_accuracy: 0.5619 - val_f1_m: 0.6145 - val_precision_m: 0.5909 - val_recall_m: 0.6416\n",
      "Epoch 45/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6521 - accuracy: 0.6130 - f1_m: 0.6497 - precision_m: 0.6239 - recall_m: 0.6788 - val_loss: 0.6854 - val_accuracy: 0.5581 - val_f1_m: 0.6100 - val_precision_m: 0.5884 - val_recall_m: 0.6353\n",
      "Epoch 46/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.6495 - accuracy: 0.6132 - f1_m: 0.6519 - precision_m: 0.6242 - recall_m: 0.6833 - val_loss: 0.6851 - val_accuracy: 0.5626 - val_f1_m: 0.6144 - val_precision_m: 0.5916 - val_recall_m: 0.6407\n",
      "Epoch 47/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6479 - accuracy: 0.6148 - f1_m: 0.6502 - precision_m: 0.6268 - recall_m: 0.6770 - val_loss: 0.6868 - val_accuracy: 0.5635 - val_f1_m: 0.6121 - val_precision_m: 0.5936 - val_recall_m: 0.6335\n",
      "Epoch 48/50\n",
      "4436/4436 [==============================] - 0s 45us/step - loss: 0.6515 - accuracy: 0.6092 - f1_m: 0.6465 - precision_m: 0.6211 - recall_m: 0.6759 - val_loss: 0.6873 - val_accuracy: 0.5637 - val_f1_m: 0.6162 - val_precision_m: 0.5924 - val_recall_m: 0.6432\n",
      "Epoch 49/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.6477 - accuracy: 0.6139 - f1_m: 0.6507 - precision_m: 0.6270 - recall_m: 0.6776 - val_loss: 0.6890 - val_accuracy: 0.5577 - val_f1_m: 0.6043 - val_precision_m: 0.5901 - val_recall_m: 0.6207\n",
      "Epoch 50/50\n",
      "4436/4436 [==============================] - 0s 46us/step - loss: 0.6462 - accuracy: 0.6157 - f1_m: 0.6524 - precision_m: 0.6279 - recall_m: 0.6800 - val_loss: 0.6882 - val_accuracy: 0.5615 - val_f1_m: 0.6113 - val_precision_m: 0.5930 - val_recall_m: 0.6325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f4148341f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=50,batch_size=64,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy\n",
      "4436/4436 [==============================] - 0s 32us/step\n",
      "[0.6338293309465414, 0.6394274234771729, 0.6766367554664612, 0.6469608545303345, 0.7116761207580566]\n",
      "Loss: 0.6338293309465414 \n",
      "Accuracy: 0.6394274234771729 \n",
      "F-1 Score: 0.6766367554664612 \n",
      "Recall: 0.6469608545303345 \n",
      "Precision: 0.7116761207580566\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy')\n",
    "a=model.evaluate(x_train,y_train)\n",
    "print(list(a))\n",
    "print('Loss: {} \\nAccuracy: {} \\nF-1 Score: {} \\nRecall: {} \\nPrecision: {}'.format(a[0],a[1],a[2],a[3],a[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy\n",
      "1110/1110 [==============================] - 0s 31us/step\n",
      "[0.6881616596703057, 0.5614864826202393, 0.6082202196121216, 0.5896580219268799, 0.6305160522460938]\n",
      "Loss: 0.6881616596703057 \n",
      "Accuracy: 0.5614864826202393 \n",
      "F-1 Score: 0.6082202196121216 \n",
      "Recall: 0.5896580219268799 \n",
      "Precision: 0.6305160522460938\n"
     ]
    }
   ],
   "source": [
    "print('Testing Accuracy')\n",
    "a=model.evaluate(x_test,y_test)\n",
    "print(list(a))\n",
    "print('Loss: {} \\nAccuracy: {} \\nF-1 Score: {} \\nRecall: {} \\nPrecision: {}'.format(a[0],a[1],a[2],a[3],a[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
